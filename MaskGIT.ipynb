{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eisbetterthanpi/MaskGIT/blob/main/MaskGIT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lFah_kZdIg5V"
      },
      "outputs": [],
      "source": [
        "# https://arxiv.org/pdf/2202.04200\n",
        "# VQVAE, emb to ind\n",
        "# transformer onehot index, cross entropy confidence\n",
        "# For each training step, we uniformly sample t ∈ [0, 1) and randomly generate a mask m ∈ {0, 1}^H×W with N = ⌈γHW⌉ masked values, where γ = cos(π/2 *t)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4WjXRJIXU7na"
      },
      "source": [
        "## top"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "ghQ8RSExs_A4"
      },
      "outputs": [],
      "source": [
        "# @title gdown\n",
        "import pickle\n",
        "!gdown 1fYC7rJswDFpLeyywD56bu9ZjCQEyzRvY -O buffer512.pkl # S\n",
        "with open('buffer512.pkl', 'rb') as f: buffer = pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "9UKkkuorG_b9"
      },
      "outputs": [],
      "source": [
        "# @title buffer dataloader\n",
        "# RNNs https://colab.research.google.com/drive/16DZRFsBEPMTHnjDED1xlxBDZpCmp5XGR#scrollTo=IV5HmCFv_ITo\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset\n",
        "import torchvision.transforms as transforms\n",
        "# import faiss\n",
        "import random\n",
        "import torchvision\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "\n",
        "class BufferDataset(Dataset): # https://github.com/karpathy/minGPT\n",
        "    def __init__(self, buffer, seq_len):\n",
        "        self.data = [step for episode in buffer for step in episode] # 0.00053\n",
        "        self.seq_len = seq_len\n",
        "        # self.transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "        self.transform = transforms.Compose([transforms.ToTensor()])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        state, action, reward = self.data[idx]\n",
        "        state = self.transform(state)\n",
        "        return state\n",
        "\n",
        "    def add(self, episode):\n",
        "        self.data.append(episode)\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "def imshow(img):\n",
        "    # img = img / 2 + 0.5  # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.figure(figsize=(3, 3))\n",
        "    # print(npimg.shape) # (3, 64, 64)\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "seq_len = 50 # 50\n",
        "train_data = BufferDataset(buffer, seq_len) # one line of poem is roughly 50 characters\n",
        "from torch.utils.data.dataloader import DataLoader\n",
        "batch_size = 128 # 128 512\n",
        "train_loader = DataLoader(train_data, shuffle = True, pin_memory = True, batch_size = batch_size, num_workers = 2, drop_last=True) # num_workers = 4\n",
        "\n",
        "# train_data.data = train_data.data + episode\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "aZ8q6DxC3P9B"
      },
      "outputs": [],
      "source": [
        "# @title RoPE\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "class RoPE(nn.Module): # Rotary Positional Embeddings\n",
        "    def __init__(self, dim, seq_len=512, base=10000):\n",
        "        super().__init__()\n",
        "        theta = 1.0 / (base ** (torch.arange(0, dim, step=2) / dim))\n",
        "        pos = torch.arange(seq_len).unsqueeze(1)\n",
        "        angles = (pos * theta).unsqueeze(-1) # [seq_len, 1] * [dim // 2] -> [seq_len, dim // 2, 1]\n",
        "        self.rot_emb = torch.cat([torch.sin(angles), torch.cos(angles)], dim=-1).to(device) # [seq_len, dim // 2, 2]\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch, seq_len, dim = x.shape\n",
        "        # if rot_emb.shape[0] < seq_len: self.__init__(dim, seq_len)\n",
        "        rot_emb = self.rot_emb[:seq_len].unsqueeze(0).expand(batch, -1, -1, -1) # [batch, seq_len, dim//2, 2]\n",
        "        x = x.reshape(batch, seq_len, dim // 2, 2)\n",
        "        rot_x = x * rot_emb\n",
        "        return rot_x.flatten(-2)\n",
        "\n",
        "dim=16\n",
        "seq_len=512\n",
        "rope = RoPE(dim, seq_len, base=10000)\n",
        "x = torch.rand(4,64,dim, device=device)\n",
        "out = rope(x)\n",
        "\n",
        "print(out.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "d6843kBbbd-Z"
      },
      "outputs": [],
      "source": [
        "# @title FSQ me\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "def ste_round(x): return x.round().detach() + x - x.detach()\n",
        "\n",
        "class FSQ(nn.Module):\n",
        "    def __init__(self, levels):\n",
        "        super().__init__()\n",
        "        self.levels = torch.tensor(levels, device=device)\n",
        "        self.basis = torch.cumprod(torch.tensor([*levels[1:], 1], device=device).flip(-1), dim=0).flip(-1)\n",
        "        self.half_width = (self.levels-1)/2\n",
        "        self.codebook_size = torch.prod(self.levels).item()\n",
        "        # self.codebook = self.indexes_to_codes(torch.arange(self.codebook_size, device=device))\n",
        "    @property\n",
        "    def codebook(self): return self.indexes_to_codes(torch.arange(self.codebook_size, device=device))\n",
        "\n",
        "    def forward(self, z, beta=1.0): # beta in (0,1). beta->0 => values more spread out\n",
        "        offset = (self.levels+1) % 2 /2 # .5 if even, 0 if odd\n",
        "        # bound = (F.sigmoid(2*z)-1/2) * (self.levels-beta) + offset\n",
        "        bound = (F.tanh(z)/2) * (self.levels-beta) + offset\n",
        "        quantized = ste_round(bound)\n",
        "        return (quantized-offset) / self.half_width # split [-1,1]\n",
        "\n",
        "    def codes_to_indexes(self, zhat):\n",
        "        zhat = (zhat + 1) * self.half_width\n",
        "        return (zhat * self.basis).sum(axis=-1).round().int()\n",
        "\n",
        "    def indexes_to_codes(self, indices):\n",
        "        indices = indices.unsqueeze(-1)\n",
        "        codes = torch.remainder(indices//self.basis, self.levels)\n",
        "        return codes / self.half_width - 1\n",
        "\n",
        "# fsq = FSQ(levels = [128,4,3,2])\n",
        "# # print(fsq.codebook)\n",
        "# batch_size, seq_len = 2, 4\n",
        "# # x = torch.linspace(-5,5,17).repeat(4,1).T # sig need larger variance to reach +-1\n",
        "# x = torch.linspace(-3,3,17, device=device).repeat(4,1).T\n",
        "# # x=la\n",
        "# la = fsq(x)\n",
        "# print(la)\n",
        "# lact = fsq.codes_to_indexes(la)\n",
        "# print(lact)\n",
        "# la = fsq.indexes_to_codes(lact)\n",
        "# print(la)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2nu4Dzma_cD5",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title ResBlock\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "def zero_module(module):\n",
        "    for p in module.parameters():\n",
        "        p.detach().zero_()\n",
        "    return module\n",
        "\n",
        "class ResBlock(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch=None, kernel=3):\n",
        "        super().__init__()\n",
        "        out_ch = out_ch or in_ch\n",
        "        act = nn.SiLU() #\n",
        "        # self.res_conv = nn.Conv2d(in_ch, out_ch, 1) if in_ch != out_ch else nn.Identity()\n",
        "        self.res_conv = zero_module(nn.Conv2d(in_ch, out_ch, 1) if in_ch != out_ch else nn.Identity())\n",
        "        # self.block = nn.Sequential( # best?\n",
        "        #     nn.Conv2d(in_ch, out_ch, 3, padding=1), nn.BatchNorm2d(out_ch), act,\n",
        "        #     zero_module(nn.Conv2d(out_ch, out_ch, 3, padding=1)), nn.BatchNorm2d(out_ch), act,\n",
        "        #     )\n",
        "        self.block = nn.Sequential(\n",
        "            nn.BatchNorm2d(in_ch), act, nn.Conv2d(in_ch, out_ch, kernel, padding=kernel//2),\n",
        "            nn.BatchNorm2d(out_ch), act, zero_module(nn.Conv2d(out_ch, out_ch, kernel, padding=kernel//2)),\n",
        "            )\n",
        "\n",
        "    def forward(self, x): # [b,c,h,w]\n",
        "        return self.block(x) + self.res_conv(x)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GjvZZswH1_KR",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title UpDownBlock_me\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "class PixelShuffleConv(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch=None, kernel=1, r=1):\n",
        "        super().__init__()\n",
        "        self.r = r\n",
        "        r = max(r, int(1/r))\n",
        "        out_ch = out_ch or in_ch\n",
        "        d_model = 64\n",
        "        if self.r>1: self.net = nn.Sequential(ResBlock(in_ch, out_ch*r**2, kernel), nn.PixelShuffle(r))\n",
        "        elif self.r<1: self.net = nn.Sequential(nn.PixelUnshuffle(r), ResBlock(in_ch*r**2, out_ch, kernel))\n",
        "        else: self.net = ResBlock(in_ch, out_ch, kernel)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "def adaptive_avg_pool_nd(n, x, output_size): return [nn.Identity(), F.adaptive_avg_pool1d, F.adaptive_avg_pool2d, F.adaptive_avg_pool3d][n](x, output_size)\n",
        "def adaptive_max_pool_nd(n, x, output_size): return [nn.Identity(), F.adaptive_max_pool1d, F.adaptive_max_pool2d, F.adaptive_max_pool3d][n](x, output_size)\n",
        "\n",
        "def adaptive_pool_at(x, dim, output_size, pool='avg'): # [b,c,h,w]\n",
        "    x = x.transpose(dim,-1)\n",
        "    shape = x.shape\n",
        "    parent={'avg':F.adaptive_avg_pool1d, 'max':F.adaptive_max_pool1d}[pool]\n",
        "    return parent(x.flatten(0,-2), output_size).unflatten(0, shape[:-1]).transpose(dim,-1)\n",
        "\n",
        "def shortcut_fn(x, dim=1, c=3, sp=(3,3), nd=2):\n",
        "    # x = adaptive_pool_at(x, dim, c, pool='max')\n",
        "    # x = adaptive_max_pool_nd(nd, x, sp)\n",
        "    x = adaptive_pool_at(x, dim, c, pool='avg')\n",
        "    x = adaptive_avg_pool_nd(nd, x, sp)\n",
        "    return x\n",
        "\n",
        "class UpDownBlock(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch, kernel=7, r=1):\n",
        "        super().__init__()\n",
        "        self.block = PixelShuffleConv(in_ch, out_ch, kernel=kernel, r=r)\n",
        "\n",
        "    def forward(self, x): # [b,c,h,w]\n",
        "        out = self.block(x)\n",
        "        shortcut = shortcut_fn(x, dim=1, c=out.shape[1], sp=out.shape[-2:], nd=2)\n",
        "        return out + shortcut\n",
        "\n",
        "# in_ch, out_ch = 16,3\n",
        "in_ch, out_ch = 3,16\n",
        "# model = UpDownBlock(in_ch, out_ch, r=1/2).to(device)\n",
        "model = UpDownBlock(in_ch, out_ch, r=2).to(device)\n",
        "model1 = UpDownBlock(out_ch, in_ch, r=1/2).to(device)\n",
        "\n",
        "# x = torch.rand(12, in_ch, 64,64, device=device)\n",
        "# out = model(x)\n",
        "# print(out.shape)\n",
        "\n",
        "state = buffer[12][40][0]\n",
        "transform = transforms.Compose([transforms.ToTensor()])\n",
        "x = transform(state).unsqueeze(0).to(device)#[0]\n",
        "sx = model(x)\n",
        "out = model1(sx)\n",
        "# print(x.shape,out.shape)\n",
        "\n",
        "imshow(torchvision.utils.make_grid(torch.cat([x.cpu(), out.cpu()], dim=0), nrow=2))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "CtmsyKatYT7h"
      },
      "outputs": [],
      "source": [
        "# @title AttentionBlock\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "def zero_module(module):\n",
        "    for p in module.parameters():\n",
        "        p.detach().zero_()\n",
        "    return module\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, d_model, n_heads=None, cond_dim=None, dropout=0.): # .1\n",
        "        super().__init__()\n",
        "        self.d_model, self.n_heads, self.d_head = d_model, n_heads, d_model // n_heads\n",
        "        self.cond_dim = cond_dim\n",
        "        self.q = nn.Linear(d_model, d_model, bias=False)\n",
        "        self.kv = nn.Linear(cond_dim or d_model, 2*d_model, bias=False)\n",
        "        self.lin = zero_module(nn.Linear(d_model, d_model))\n",
        "        self.drop = nn.Dropout(dropout) # indp before q,k,v; after linout\n",
        "        self.scale = self.d_head**-.5\n",
        "\n",
        "    def forward(self, x, cond=None, mask=None): # [batch, T, d_model]=[batch, h*w, c], [batch, num_tok, cond_dim], [batch,T]\n",
        "        if self.cond_dim==None: cond=x # is self attn\n",
        "        q = self.q(x).unflatten(-1, (self.n_heads, self.d_head)).transpose(1, 2) # [batch, T, d_model] -> [batch, n_heads, T, d_head]\n",
        "        # K = self.k(x).unflatten(-1, (self.n_heads, self.d_head)).transpose(1, 2)\n",
        "        k, v = self.kv(cond).unflatten(-1, (self.n_heads, 2*self.d_head)).transpose(1, 2).chunk(2, dim=-1) # [batch, n_heads, T/num_tok, d_head]\n",
        "\n",
        "        # # linear attention # Softmax(q) @ (Softmax(k).T @ v)\n",
        "        if mask != None:\n",
        "            mask = mask[:, None, :, None] # [batch,T] -> [batch,1,T,1]\n",
        "            k, v = k.masked_fill(mask, -torch.finfo(x.dtype).max), v.masked_fill(mask, -torch.finfo(x.dtype).max)\n",
        "        q, k = q.softmax(dim=-1)*self.scale, k.softmax(dim=-2)\n",
        "        context = k.transpose(-2,-1) @ v # [batch, n_heads, d_head, d_head]\n",
        "        out = q @ context # [batch, n_heads, T/num_tok, d_head]\n",
        "\n",
        "        # # (quadratic) attention # Softmax(q @ k.T) @ v\n",
        "        # out = F.scaled_dot_product_attention(q, k, v, attn_mask=mask.unsqueeze(1) if mask != None else None, dropout_p=0) # mask: [batch,len_q, len_v]\n",
        "        # out = F.scaled_dot_product_attention(q, k, v, is_causal=True, dropout_p=0) # mask: [batch,len_q, len_v]\n",
        "        # attn = q @ k.transpose(-2,-1) * self.scale # [batch, n_heads, T] # [batch, n_heads, T, T/num_tok]\n",
        "        # # if mask != None: attn = attn.masked_fill(mask[:, None, :, None], -torch.finfo(attn.dtype).max) # [batch,T]->[batch,1,T,1]\n",
        "        # if mask != None: attn = attn.masked_fill(mask.unsqueeze(1), -torch.finfo(attn.dtype).max) # [b,t,t]->[b,1,t,t]\n",
        "        # attention = torch.softmax(attn, dim=-1)\n",
        "        # out = self.drop(attention) @ v # [batch, n_heads, T, d_head]\n",
        "\n",
        "        out = out.transpose(1,2).flatten(2)\n",
        "        return self.drop(self.lin(out)) # [batch, T, d_model]\n",
        "\n",
        "class AttentionBlock(nn.Module):\n",
        "    def __init__(self, d_model, n_heads, cond_dim=None, mult=4, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.d_model = d_model\n",
        "        self.norm = nn.RMSNorm(d_model) # LayerNorm RMSNorm\n",
        "        self.drop = nn.Dropout(dropout)\n",
        "        self.cond_dim = cond_dim\n",
        "        self.attn = MultiHeadAttention(d_model, n_heads=n_heads, dropout=0) # 16448\n",
        "        act = nn.GELU() # ReLU GELU\n",
        "        ff_dim = d_model * mult\n",
        "        self.ff = nn.Sequential(\n",
        "            nn.RMSNorm(d_model), nn.Linear(d_model, ff_dim), act,\n",
        "            nn.RMSNorm(ff_dim), nn.Dropout(dropout), zero_module(nn.Linear(ff_dim, d_model))\n",
        "        )\n",
        "\n",
        "    def forward(self, x, cond=None, mask=None): # [b,c,h,w], [batch, num_tok, cond_dim], [batch,T]\n",
        "        # if self.cond_dim==None: cond=None # is self attn\n",
        "        x = x + self.drop(self.attn(self.norm(x)))\n",
        "        x = x + self.drop(self.ff(x))\n",
        "        return x\n",
        "\n",
        "\n",
        "import inspect\n",
        "class Seq(nn.Sequential):\n",
        "    def __init__(self, *args):\n",
        "        super().__init__(*args)\n",
        "        for layer in self:\n",
        "            params = inspect.signature(layer.forward).parameters.keys()\n",
        "            layer._fwdparams = ','.join(params)\n",
        "\n",
        "    def forward(self, x, mask=None):\n",
        "        for layer in self:\n",
        "            args = [x]\n",
        "            if 'mask' in layer._fwdparams: args.append(mask)\n",
        "            x = layer(*args)\n",
        "        return x\n",
        "\n",
        "\n",
        "# d_model=64\n",
        "# in_dim=16\n",
        "# x = torch.rand(64, 3, d_model, device=device)\n",
        "# model = AttentionBlock(d_model, n_heads=8)\n",
        "# logits = model(x)\n",
        "# print(logits.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LA5BkvSrU4n-"
      },
      "source": [
        "##sv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pexEnGZesxBC",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title transformer\n",
        "\n",
        "def complement(x, length): # [b,t], int\n",
        "    b = x.shape[0]\n",
        "    device = x.device\n",
        "    full = torch.arange(length, device=device).repeat(b,1)   # (length,)\n",
        "    mask = torch.ones(b, length, dtype=bool, device=device)\n",
        "    mask[torch.arange(b).unsqueeze(-1), x] = False\n",
        "    return full[mask].reshape(b,-1)\n",
        "\n",
        "# b = 2\n",
        "# msk_len=4\n",
        "# x = torch.stack([torch.randperm(10)[:msk_len] for _ in range(b)]) # [b,msk_len]\n",
        "# print(x)\n",
        "# print(complement(x,10))\n",
        "\n",
        "class Transformer(nn.Module):\n",
        "    def __init__(self, in_dim, d_model=64, out_dim=None, n_heads=8, n_layers=1, ff_dim=256, dropout=0):\n",
        "        super().__init__()\n",
        "        self.tok_emb = nn.Embedding(in_dim, d_model)\n",
        "        # self.tok_emb = nn.Linear(in_dim, d_model)\n",
        "        # self.pos_enc = RoPE(d_model, base=10000)\n",
        "        self.pos_emb = nn.Parameter(torch.randn(1, 2000, d_model)*.02)\n",
        "        self.block = Seq(*[AttentionBlock(d_model, n_heads, ff_dim, dropout) for _ in range(n_layers)])\n",
        "        self.out = nn.Linear(d_model, out_dim or in_dim)\n",
        "        self.cls = nn.Parameter(torch.randn(1,1,d_model)*0.02) # randn zeros\n",
        "\n",
        "    def forward(self, x, knw_mask=None, unk_mask=None): # [b,t], [b,t,t]\n",
        "        x = self.tok_emb(x)\n",
        "        b,t,_ = x.shape\n",
        "        x = x + self.pos_emb[0,:t]\n",
        "        # if knw_mask!=None and unk_mask!=None:\n",
        "        if knw_mask!=None:\n",
        "            x = x[torch.arange(b).unsqueeze(-1), knw_mask] # [batch, num_context_toks, d_model]\n",
        "            # print('trans fwd', x.shape, self.pos_emb[0,knw_mask].shape)\n",
        "            # x = x + self.pos_emb[0,knw_mask]\n",
        "\n",
        "            if unk_mask==None: unk_mask = complement(knw_mask,t)\n",
        "            pred_tokens = self.cls + self.pos_emb[0,unk_mask]\n",
        "            # print('trans fwd', x.shape, pred_tokens.shape)\n",
        "            x = torch.cat([x, pred_tokens], dim=1) # [batch, seq_len+num_trg_toks, d_model]\n",
        "            ids = torch.cat([knw_mask,unk_mask], dim=1)\n",
        "            # print('trans fwd', x.shape, ids[0], max(ids[0]))\n",
        "            # x = torch.zeros_like(x).scatter(1, ids.unsqueeze(-1).repeat(1,1,x.shape[-1]), x)\n",
        "            o = torch.empty_like(x)\n",
        "            o[torch.arange(b).unsqueeze(-1), ids] = x\n",
        "            x = o\n",
        "        x = self.block(x)\n",
        "        x = self.out(x)\n",
        "        return x\n",
        "\n",
        "d_model=4\n",
        "in_dim=16\n",
        "b,t=2,10\n",
        "x = torch.randint(0, in_dim, (b, t), device=device)\n",
        "# x = torch.rand(b,t,in_dim, device=device)\n",
        "# model = Transformer(in_dim, d_model, out_dim=None, n_heads=8, n_layers=1)\n",
        "model = Transformer(in_dim, d_model, out_dim=None, n_heads=1, n_layers=1).to(device)\n",
        "# print(sum(p.numel() for p in model.parameters() if p.requires_grad)) # 59850\n",
        "\n",
        "mask = torch.stack([torch.randperm(t)[:t] for _ in range(b)]).to(device)\n",
        "# print(x)\n",
        "print(mask)\n",
        "\n",
        "# logits = model(x)\n",
        "logits = model(x, mask)\n",
        "print(logits.shape)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title random_masking\n",
        "import torch\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "def random_masking(length, mask_ratio, b=64):\n",
        "    noise = torch.rand(b, length, device=device)\n",
        "    len_mask = int(length * mask_ratio)\n",
        "    _, msk_ind = torch.topk(noise, k=len_mask, dim=-1, sorted=False) # val, ind -> [b,len_mask]\n",
        "    _, keep_ind = torch.topk(noise, k=length-len_mask, largest=False, dim=-1, sorted=False) # val, ind -> [b,len_keep]\n",
        "    return msk_ind, keep_ind\n",
        "\n",
        "# msk_ind, keep_ind = random_masking(10, .3, b=2)\n",
        "\n",
        "# x_ = torch.rand(4, 3, 2)\n",
        "# print(x_)\n",
        "# # ids = torch.tensor([0, 2, 1])[None,:,None]\n",
        "# # ids = torch.tensor([0, 2, 1])[None,:,None].repeat(4,1,2)\n",
        "# ids = torch.tensor([1, 2, 0])[None,:,None].repeat(4,1,2)\n",
        "# # o = torch.gather(x_, dim=1, index=ids)\n",
        "# o = torch.zeros_like(x_).scatter_(dim=1, index=ids, src=x_)\n",
        "# print(o)\n"
      ],
      "metadata": {
        "id": "k3nfeLM4wtkJ",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_O9NnnDvZI37",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title MaskGIT\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "def Cosine(x): # in [0,1]\n",
        "    # k = unk_len*jax.lax.cos(math.pi/2 * ratio).clamp(1e-6, 1.)\n",
        "    # torch.tensor(x)\n",
        "    return torch.cos(torch.pi*x/2).clamp(0,1)\n",
        "\n",
        "class MaskGIT(nn.Module):\n",
        "    def __init__(self, in_ch=16, d_model=64, z_dim=3, n_head=8):\n",
        "        super().__init__()\n",
        "        # z_dim = z_dim or in_ch # z_channels z_dim\n",
        "        self.encoder = nn.Sequential(\n",
        "            UpDownBlock(in_ch, d_model, r=1/2),\n",
        "            UpDownBlock(d_model, z_dim, r=1/2),\n",
        "        )\n",
        "        self.decoder = nn.Sequential(\n",
        "            UpDownBlock(z_dim, d_model, r=2),\n",
        "            UpDownBlock(d_model, in_ch, r=2),\n",
        "        )\n",
        "        self.vq = FSQ(levels = z_dim*[6]) # 1024\n",
        "        self.transformer = Transformer(6**z_dim, d_model, out_dim=None, n_heads=n_head, n_layers=1)\n",
        "        # self.transformer = Transformer(z_dim, d_model, out_dim=None, n_heads=n_head, n_layers=1)\n",
        "\n",
        "    def loss(self, img, mask_len=None): # [b,c,h,w]\n",
        "        x = self.encoder(img)\n",
        "        bchw = x.shape\n",
        "        # print('mskgit fwd', x.shape)\n",
        "        z = self.vq(x.flatten(2).transpose(-2,-1)) # [b,t,d]\n",
        "        b,t,_ = z.shape\n",
        "        y = x = self.vq.codes_to_indexes(z) # [b,t]\n",
        "\n",
        "        mask_len = mask_len or (Cosine(torch.rand(1))*t).int()\n",
        "        knw_mask, unk_mask = random_masking(t, torch.rand(1), b=b)\n",
        "\n",
        "        x = self.transformer(x, knw_mask, unk_mask)\n",
        "        # print('mskgit fwd', x.shape, y.shape)\n",
        "        trans_loss = F.cross_entropy(x[torch.arange(b).unsqueeze(-1), unk_mask].flatten(0,1), y.long()[torch.arange(b).unsqueeze(-1), unk_mask].flatten())\n",
        "\n",
        "        z = z.transpose(-2,-1).reshape(*bchw)\n",
        "        img_ = self.decoder(z)\n",
        "        vqvae_loss = F.mse_loss(img, img_)\n",
        "        # return trans_loss + vqvae_loss\n",
        "        return trans_loss, vqvae_loss\n",
        "\n",
        "    # def loss(self, img, mask_len=None): # [b,c,h,w]\n",
        "    #     x = self.encoder(img)\n",
        "    #     bchw = x.shape\n",
        "    #     # z = self.vq(x.flatten(2).transpose(-2,-1)) # [b,t,d]\n",
        "    #     # z = z.transpose(-2,-1).reshape(*bchw)\n",
        "    #     z = x\n",
        "    #     img_ = self.decoder(z)\n",
        "    #     vqvae_loss = F.mse_loss(img, img_)\n",
        "    #     return vqvae_loss\n",
        "\n",
        "\n",
        "    def decode(self, x, num_iter=12, temperature=1., start=.1):\n",
        "        b,c,h,w = x.shape\n",
        "        x = self.vq(x.flatten(2).transpose(-2,-1)) # [b,t,d]\n",
        "        x = self.vq.codes_to_indexes(x) # [b,t]\n",
        "\n",
        "        knw_mask, unk_mask = random_masking(x.shape[1], start, b=b)\n",
        "        # knw_mask, unk_mask = None, torch.arange(x.shape[1]).repeat(b,1).to(device)\n",
        "\n",
        "        mask_len = (Cosine(torch.linspace(0,1,num_iter+1))*unk_mask.shape[1]).int()\n",
        "        for i, (ksel, kunk) in enumerate(zip(mask_len[:-1]-mask_len[1:], mask_len[1:])):\n",
        "            # print('ksel, kunk',ksel, kunk)\n",
        "            logits = self.transformer(x, knw_mask, unk_mask) # [b,t,vocab_size]\n",
        "            logits = logits[torch.arange(b).unsqueeze(-1), unk_mask]\n",
        "            # print(logits.shape)\n",
        "            probs = F.softmax(logits/temperature, dim=-1).flatten(0,1) # [b*num_unk, vocab_size]\n",
        "            sampled_toks = torch.multinomial(probs, num_samples=1) # [b*num_unk, 1] rand sample by output distribution\n",
        "            selected_probs = probs.gather(-1, sampled_toks).reshape(b,-1) # [b, num_unk] confidence of selected toks\n",
        "            sampled_toks = sampled_toks.reshape(b,-1).int()\n",
        "            _, sel_ind = torch.topk(selected_probs, k=ksel, dim=-1, sorted=False) # val, ind -> [b,k]\n",
        "            _, unk_ind = torch.topk(selected_probs, k=kunk, largest=False, dim=-1, sorted=False) # val, ind -> [b,k]\n",
        "\n",
        "            sel_mask, unk_mask = unk_mask[torch.arange(b).unsqueeze(-1), sel_ind], unk_mask[torch.arange(b).unsqueeze(-1), unk_ind]\n",
        "            sel_tok = sampled_toks[torch.arange(b).unsqueeze(-1), sel_ind]\n",
        "\n",
        "            # print('mskgit fwd', x.shape, sel_mask.shape, sel_tok.shape) # [b,t,vocab_size]\n",
        "            x[torch.arange(b).unsqueeze(-1), sel_mask] = sel_tok # [b,t]/\n",
        "\n",
        "            # if knw_mask==None: knw_mask = sel_mask ; else:\n",
        "            knw_mask = torch.cat([knw_mask, sel_mask], dim=1)\n",
        "\n",
        "        x = self.vq.indexes_to_codes(x) # [b,t]\n",
        "        x = x.transpose(-2,-1).reshape(b,c,h,w)\n",
        "        return x\n",
        "\n",
        "# start with known toks(bec rest is unk tok), -model> logits, sample to sampled toks\n",
        "# probs=softmax(logits). selected_probs = probs of selected ind\n",
        "# topk by confidence = jnp.log(selected_probs) + temperature * jax.random.gumbel(rng, probs.shape)\n",
        "\n",
        "\n",
        "batch=25#64\n",
        "in_ch=3\n",
        "d_model=64\n",
        "z_dim=4\n",
        "h,w = 64,64\n",
        "model = MaskGIT(in_ch, d_model, z_dim=z_dim, n_head=8).to(device)\n",
        "\n",
        "x = torch.rand((batch, in_ch, h, w), device=device)\n",
        "\n",
        "# out = model(x)\n",
        "out = model.loss(x)\n",
        "# out = model.encode(x)\n",
        "# print(out.shape)\n",
        "\n",
        "# x = torch.rand(64, 3, d_model, device=device)\n",
        "# out = torch.randint(0, in_dim, (64, 3), device=device)\n",
        "\n",
        "sx = model.encoder(x)\n",
        "sx_ = model.decode(sx)\n",
        "x_ = model.decoder(sx_)\n",
        "# # x = model.quantise(x)\n",
        "print(x_.shape)\n",
        "\n",
        "optim = torch.optim.AdamW(model.parameters(), lr=1e-3)\n",
        "print(sum(p.numel() for p in model.parameters() if p.requires_grad)) # 19683\n",
        "print(sum(p.numel() for p in model.transformer.parameters() if p.requires_grad)) # 19683\n",
        "print(sum(p.numel() for p in model.encoder.parameters() if p.requires_grad)) # 19683\n",
        "print(sum(p.numel() for p in model.decoder.parameters() if p.requires_grad)) # 19683\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "2Nd-sGe6Ku4S"
      },
      "outputs": [],
      "source": [
        "# @title wandb\n",
        "!pip install -q wandb\n",
        "import wandb # https://docs.wandb.ai/quickstart\n",
        "wandb.login(key='487a2109e55dce4e13fc70681781de9f50f27be7')\n",
        "try: run.finish()\n",
        "except NameError: pass\n",
        "run = wandb.init(project=\"maskgit\", config={\"model\": \"res18\",})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rJQDMix9EpYZ"
      },
      "outputs": [],
      "source": [
        "# @title train\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "torch.backends.cuda.matmul.allow_tf32 = True\n",
        "torch.backends.cudnn.allow_tf32 = True\n",
        "scaler = torch.GradScaler(device)\n",
        "\n",
        "def train(model, optim, dataloader, scheduler=None):\n",
        "    model.train()\n",
        "    for i, x in enumerate(dataloader):\n",
        "        x = x.to(device)\n",
        "        with torch.autocast(device_type=device, dtype=torch.bfloat16): # float16 cannot?\n",
        "            # loss = model.loss(x)\n",
        "            trans_loss, vqvae_loss = model.loss(x)\n",
        "            loss = trans_loss + vqvae_loss\n",
        "        optim.zero_grad()\n",
        "        scaler.scale(loss).backward()\n",
        "        # torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)  # clip gradients\n",
        "        scaler.step(optim)\n",
        "        scaler.update()\n",
        "\n",
        "        if scheduler is not None: scheduler.step()\n",
        "        # try: wandb.log({\"loss\": loss.item()})\n",
        "        try: wandb.log({\"trans_loss\": trans_loss.item(), \"vqvae_loss\": vqvae_loss.item()})\n",
        "        except NameError: pass\n",
        "        # if i % 100 == 0: print(loss.item())\n",
        "        if i % 100 == 0: print(\"trans_loss\", trans_loss.item(), \"vqvae_loss\", vqvae_loss.item())\n",
        "\n",
        "\n",
        "# for i in range(1):\n",
        "for i in range(10): # 10\n",
        "    print(i)\n",
        "    train(model, optim, train_loader)\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        state = buffer[12][40][0]\n",
        "        transform = transforms.Compose([transforms.ToTensor()])\n",
        "        x = transform(state).unsqueeze(0).to(device)\n",
        "        sx = model.encoder(x)\n",
        "        x_ = model.decoder(sx)\n",
        "        sx_ = model.decode(sx)\n",
        "        out = model.decoder(sx_)\n",
        "\n",
        "        # imshow(torchvision.utils.make_grid(sx.cpu()))\n",
        "        # imshow(torchvision.utils.make_grid(torch.cat([x.cpu(), sx_.cpu()], dim=0), nrow=2))\n",
        "        imshow(torchvision.utils.make_grid(torch.cat([x.cpu(), x_.cpu(), out.cpu()], dim=0), nrow=3))\n",
        "        imshow(torchvision.utils.make_grid(torch.cat([sx.cpu(), sx_.cpu()], dim=0), nrow=2))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "def imshow(img):\n",
        "    # img = img / 2 + 0.5  # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.figure(figsize=(10, 3))\n",
        "    # print(npimg.shape) # (3, 64, 64)\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    state = buffer[12][40][0]\n",
        "    transform = transforms.Compose([transforms.ToTensor()])\n",
        "    x = transform(state).unsqueeze(0).to(device)#[0]\n",
        "    sx = model.encoder(x)\n",
        "    x_ = model.decoder(sx)\n",
        "    # sx_ = model.decode(sx, num_iter=12, temperature=1., start=.5)\n",
        "    # out = model.decoder(sx_)\n",
        "\n",
        "    print(x.shape, x_.shape, sx.shape, sx_.shape, out.shape)\n",
        "\n",
        "    # imshow(torchvision.utils.make_grid(x.cpu()))\n",
        "    imshow(torchvision.utils.make_grid(sx.cpu()))\n",
        "    imshow(torchvision.utils.make_grid(torch.cat([x.cpu(), out.cpu()], dim=0), nrow=2))\n",
        "    # imshow(torchvision.utils.make_grid(torch.cat([x.cpu(), x_.cpu(), out.cpu()], dim=0), nrow=3))\n",
        "    # imshow(torchvision.utils.make_grid(torch.cat([sx.cpu(), sx_.cpu()], dim=0), nrow=2))\n",
        "    # imshow(torchvision.utils.make_grid(out.cpu()))\n"
      ],
      "metadata": {
        "id": "ywBUYSaYLRcx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JT8AgOx0E_KM"
      },
      "outputs": [],
      "source": [
        "# @title save/load\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "# folder='/content/drive/MyDrive/jepa/'\n",
        "\n",
        "# modelsd, optimsd = torch.load(folder+'maskgit.pkl', map_location=device).values()\n",
        "modelsd, optimsd = torch.load('maskgit.pkl', map_location=device).values()\n",
        "model.load_state_dict(modelsd, strict=False)\n",
        "optim.load_state_dict(optimsd)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint = {'model': model.state_dict(), 'optimizer': optim.state_dict()}\n",
        "# checkpoint = {'model': model_mlm.state_dict()}\n",
        "# torch.save(checkpoint, folder+'maskgit.pkl')\n",
        "torch.save(checkpoint, 'maskgit.pkl')"
      ],
      "metadata": {
        "id": "5fFr5dco-5E6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## drawer"
      ],
      "metadata": {
        "id": "EhSU2YKrbt6K"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N6PckjjKVp4i"
      },
      "outputs": [],
      "source": [
        "\n",
        "def entropy(scores): # [batch, seq_len, vocab]\n",
        "    \"\"\"Computes the entropy for each token in the batch. Note: uses natural log.\"\"\"\n",
        "    log_probs = F.log_softmax(scores, dim=-1)\n",
        "    probs = torch.exp(log_probs)\n",
        "    p_log_p = log_probs * probs\n",
        "    entropy = -p_log_p.sum(dim=-1)\n",
        "    return entropy # [batch, seq_len]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7MuA_JN8yrZu"
      },
      "outputs": [],
      "source": [
        "t=1024\n",
        "b=128\n",
        "x=torch.rand(b,t,128)\n",
        "# print(x)\n",
        "mask = torch.stack([torch.randperm(t)[:t] for _ in range(b)])\n",
        "# print(mask)\n",
        "# x = x.gather(1, mask.unsqueeze(-1))\n",
        "o = torch.zeros_like(x).scatter(1, mask.unsqueeze(-1).repeat(1,1,x.shape[-1]), x) # unsort from inds\n",
        "# print(o)\n",
        "o = torch.empty_like(x)\n",
        "x[torch.arange(b).unsqueeze(-1), mask] = x\n",
        "# print(o)\n",
        "# %timeit o = torch.zeros_like(x).scatter(1, mask.unsqueeze(-1).repeat(1,1,x.shape[-1]), x) # 3.51 ms\n",
        "%timeit o = torch.empty_like(x);o[torch.arange(b).unsqueeze(-1), mask] = x # 3.92 ms 5.19 6.21\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hwsS0yNYFGAx",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title multiblock2d\n",
        "def multiblock2d(hw=(8,8), scale=(.15,.2), aspect_ratio=(.75,1.5), M=1):\n",
        "    mask_aspect = torch.rand(1) * (aspect_ratio[1] - aspect_ratio[0]) + aspect_ratio[0] # in (min_s, max_s) # all blocks same size\n",
        "    mask_scale = torch.rand(1) * (scale[1] - scale[0]) + scale[0] # in (min_s, max_s) # all blocks same size\n",
        "    h = (mask_scale/mask_aspect)**.5# h*(h*aspect) = scale\n",
        "    w = h * mask_aspect\n",
        "    # h_pos, w_pos = torch.rand(M)*(1-w), torch.rand(M)*(1-h) # in (0, 1 - mask_len)\n",
        "    # h_len, h_pos = (h*hw[0]).int(), h_pos*hw[0]\n",
        "    # w_len, w_pos = (w*hw[1]).int(), w_pos*hw[1]\n",
        "\n",
        "    h_len, w_len = (h*hw[0]).int(), (w*hw[1]).int()\n",
        "    h_pos, w_pos = torch.rand(M)*(hw[1]-w_len), torch.rand(M)*(hw[0]-h_len) # in (0, 1 - mask_len)\n",
        "\n",
        "\n",
        "    h_ind, w_ind = torch.arange(hw[0]).unsqueeze(0), torch.arange(hw[1]).unsqueeze(0) # [1, seq]\n",
        "    h_mask = (h_ind>=h_pos.unsqueeze(-1)) & (h_ind<(h_pos+h_len).unsqueeze(-1)) # [M, seq]\n",
        "    w_mask = (w_ind>=w_pos.unsqueeze(-1)) & (w_ind<(w_pos+w_len).unsqueeze(-1)) # [M, seq]\n",
        "    target_mask = h_mask.unsqueeze(-1) & w_mask.unsqueeze(-2) # [M, seq, seq]\n",
        "    return target_mask\n",
        "\n",
        "# b=25\n",
        "# mask = multiblock2d(hw=(8,8), scale=(.15,.2), aspect_ratio=(.75,1.5), M=b)#.squeeze(0)\n",
        "# print(mask)\n",
        "# # print(mask.flatten(1).sum(1))\n",
        "# print(mask.flatten(1).nonzero()[:,1].reshape(b,-1).shape)\n",
        "# # mask = mask.flatten(1).nonzero()[:,1].reshape(b,-1)\n",
        "# # mask = mask.flatten().nonzero().reshape(1,-1)\n",
        "# # mask = mask.nonzero().reshape(1,-1)\n",
        "# # print(mask)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WuXDKUIACl91"
      },
      "outputs": [],
      "source": [
        "# @title VQVAE me\n",
        "\n",
        "class VQVAE(nn.Module):\n",
        "    def __init__(self, in_ch=3, d_model=16, out_ch=None, depth=4, num_res_blocks=1, n_head=-1, d_head=4):\n",
        "        super().__init__()\n",
        "        self.in_ch = in_ch\n",
        "        self.d_model = d_model # base channel count for the model\n",
        "        out_ch = out_ch or in_ch # z_channels z_dim\n",
        "        # n_head = d_model // d_head\n",
        "        # self.vq = FSQ(levels = z_dim*[32])\n",
        "\n",
        "        mult = [1,1,1,1]\n",
        "        # mult = [1,2,3,4] # [1,2,3,4] [1,2,2,2]\n",
        "        ch_list = [d_model * m for m in mult] # [128, 256, 384, 512]\n",
        "\n",
        "        self.encoder = nn.Sequential(\n",
        "            # nn.Conv2d(in_ch, ch_list[0], 3, 1, padding=3//2),\n",
        "\n",
        "            ResBlock(in_ch, ch_list[0]),\n",
        "            # ResBlock(ch_list[0], ch_list[1]),\n",
        "            # ResBlock(ch_list[1], ch_list[1]),\n",
        "            AttentionBlock(ch_list[0], d_head),\n",
        "\n",
        "            # nn.PixelUnshuffle(2),\n",
        "            # ResBlock(ch_list[0]*2**2, ch_list[1]),\n",
        "            # nn.AvgPool2d(2,2),\n",
        "            # nn.MaxPool2d(2,2),\n",
        "            UpDownBlock(3, ch_list[0], r=1/2),\n",
        "\n",
        "            ResBlock(ch_list[0], ch_list[1]),\n",
        "            # ResBlock(ch_list[2], ch_list[2]),\n",
        "            AttentionBlock(ch_list[1], d_head),\n",
        "            # ResBlock(ch_list[1], ch_list[2]),\n",
        "\n",
        "            # nn.PixelUnshuffle(2),\n",
        "            # ResBlock(ch_list[2]*2**2, ch_list[3]),\n",
        "            # nn.AvgPool2d(2,2),\n",
        "            UpDownBlock(ch_list[0], out_ch, r=1/2),\n",
        "\n",
        "            ResBlock(ch_list[2], ch_list[3]),\n",
        "            AttentionBlock(ch_list[3], d_head),\n",
        "            # ResBlock(ch_list[3], ch_list[3]),\n",
        "            ResBlock(ch_list[3], out_ch),\n",
        "\n",
        "            # # nn.GroupNorm(32, ch_list[-1]), nn.SiLU(), nn.Conv2d(ch_list[-1], out_ch, 3, 1, padding=3//2)\n",
        "            # nn.BatchNorm2d(ch_list[-1]), nn.SiLU(), nn.Conv2d(ch_list[-1], out_ch, 3, 1, padding=3//2)\n",
        "        )\n",
        "\n",
        "        self.decoder = nn.Sequential(\n",
        "            # nn.Conv2d(out_ch, ch_list[-1], 3, 1, padding=3//2),\n",
        "\n",
        "            ResBlock(out_ch, ch_list[3]),\n",
        "            # ResBlock(ch_list[3], ch_list[3]),\n",
        "            AttentionBlock(ch_list[3], d_head),\n",
        "            ResBlock(ch_list[3], ch_list[2]),\n",
        "            # nn.Upsample(scale_factor=2, mode='nearest'),\n",
        "            UpDownBlock(out_ch, ch_list[0], r=2),\n",
        "\n",
        "            # ResBlock(ch_list[3], ch_list[2]*2**2),\n",
        "            # # AttentionBlock(ch_list[2]*2**2, d_head),\n",
        "            # nn.PixelShuffle(2),\n",
        "\n",
        "            ResBlock(ch_list[2], ch_list[1]),\n",
        "            AttentionBlock(ch_list[2], d_head),\n",
        "            # ResBlock(ch_list[1], ch_list[0]),\n",
        "            # nn.Upsample(scale_factor=2, mode='nearest'),\n",
        "            UpDownBlock(ch_list[0], in_ch, r=2),\n",
        "            # ResBlock(ch_list[1], ch_list[0]*2**2),\n",
        "            # nn.PixelShuffle(2),\n",
        "\n",
        "            ResBlock(ch_list[1], ch_list[0]),\n",
        "            AttentionBlock(ch_list[0], d_head),\n",
        "            ResBlock(ch_list[0], in_ch),\n",
        "\n",
        "            # # nn.GroupNorm(32, ch_list[0]), nn.SiLU(), nn.Conv2d(ch_list[0], in_ch, 3, 1, padding=3//2)\n",
        "            # nn.BatchNorm2d(ch_list[0]), nn.SiLU(), zero_module(nn.Conv2d(ch_list[0], in_ch, 3, 1, padding=3//2)) # zero\n",
        "        )\n",
        "\n",
        "    # def forward(self, x):\n",
        "    #     x = self.encoder(x)\n",
        "    #     # print(x.shape)\n",
        "    #     commitment_loss, x, _ = self.vq(x)\n",
        "    #     # print(x.shape)\n",
        "    #     x = self.decoder(x)\n",
        "    #     return x, commitment_loss\n",
        "\n",
        "    # def encode(self, x):\n",
        "    #     x = self.encoder(x)\n",
        "    #     _, x, _ = self.vq(x)\n",
        "    #     return x\n",
        "\n",
        "    # def decode(self, x):\n",
        "    #     _, x, _ = self.vq(x)\n",
        "    #     return self.decoder(x)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.encoder(x)\n",
        "        # x = self.quantise(x)\n",
        "        # print(x.shape)\n",
        "        x = self.decoder(x)\n",
        "        return x\n",
        "\n",
        "    def encode(self, x):\n",
        "        x = self.encoder(x)\n",
        "        # return self.quantise(x)\n",
        "        return x\n",
        "    def decode(self, x):\n",
        "        # _, x, _ = self.vq(x)\n",
        "        # x = self.quantise(x)\n",
        "        return self.decoder(x)\n",
        "    def quantise(self, x): # [b,c,h,w]->[b,h,w,c]->[b,c,h,w]\n",
        "        return self.vq(x.permute(0,2,3,1)).permute(0,3,1,2)\n",
        "\n",
        "\n",
        "\n",
        "batch=2\n",
        "in_ch=3\n",
        "z_dim=3\n",
        "h,w = 64,64\n",
        "model = VQVAE(in_ch, d_model=16, out_ch=z_dim, depth=4, num_res_blocks=1, n_head=-1, d_head=4).to(device)\n",
        "optim = torch.optim.AdamW(model.parameters(), lr=1e-3)\n",
        "print(sum(p.numel() for p in model.parameters() if p.requires_grad)) # 19683\n",
        "\n",
        "x = torch.rand((batch, in_ch, h, w), device=device)\n",
        "# out, _ = model(x)\n",
        "# print(out.shape)\n",
        "# x = model.quantise(x)\n",
        "# print(x.shape)\n",
        "# print(x)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "y7CtfbCdIpCG"
      },
      "outputs": [],
      "source": [
        "# @title mit-han-lab/efficientvit dc_ae.py down\n",
        "# https://github.com/mit-han-lab/efficientvit/blob/master/efficientvit/models/efficientvit/dc_ae.py\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class DCAE(nn.Module):\n",
        "    def __init__(self, in_ch=3, out_ch=4, d_model=16, mult=[1], depth_list=[1,1]):\n",
        "        super().__init__()\n",
        "        width_list=[d_model*m for m in mult]\n",
        "        # encoder mult=[1,2,4,4,8,8] # depth_list=[0,4,8,2,2,2]\n",
        "        # decoder mult=[1,2,4,4,8,8] # depth_list=[0,5,10,2,2,2]\n",
        "\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv2d(in_ch, width_list[0], 3, 2, padding=3//2),\n",
        "\n",
        "            UpDownBlock(width_list[0], width_list[0], r=1/2),\n",
        "            ResBlock(width_list[0]),\n",
        "            UpDownBlock(width_list[0], width_list[-1], r=1/2),\n",
        "            ResBlock(width_list[-1]),\n",
        "            AttentionBlock(width_list[-1], d_head=4),\n",
        "            UpDownBlock(width_list[-1], out_ch, r=1),\n",
        "        )\n",
        "        self.decoder = nn.Sequential(\n",
        "            UpDownBlock(out_ch, width_list[-1], r=1),\n",
        "            AttentionBlock(width_list[-1], d_head=4),\n",
        "            ResBlock(width_list[-1]),\n",
        "            UpDownBlock(width_list[-1], width_list[0], r=2),\n",
        "            ResBlock(width_list[0]),\n",
        "            nn.BatchNorm2d(width_list[0]), nn.ReLU(), UpDownBlock(width_list[0], width_list[0], r=2),\n",
        "            nn.ConvTranspose2d(width_list[0], in_ch, 3, 2, padding=3//2, output_padding=1),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.encoder(x)\n",
        "        x = self.decoder(x)\n",
        "        return x\n",
        "\n",
        "in_ch=3\n",
        "out_ch=3\n",
        "# 3*2^2|d_model\n",
        "model = DCAE(in_ch, out_ch, d_model=16, mult=[1,1], depth_list=[1,1]).to(device)\n",
        "# print(sum(p.numel() for p in model.stages.parameters() if p.requires_grad)) # 4393984\n",
        "print(sum(p.numel() for p in model.parameters() if p.requires_grad)) # 19683\n",
        "optim = torch.optim.AdamW(model.parameters(), lr=1e-3)\n",
        "x = torch.rand((2,in_ch,64,64), device=device)\n",
        "sx = model.encoder(x)\n",
        "print(sx.shape)\n",
        "out = model.decoder(sx)\n",
        "# out = model(x)\n",
        "print(out.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sND7C1rq4nEg"
      },
      "source": [
        "## other maskgit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "3hskWLVg8Ynm"
      },
      "outputs": [],
      "source": [
        "# @title google-research parallel_decode.py down\n",
        "# https://github.com/google-research/maskgit/blob/main/maskgit/libml/parallel_decode.py\n",
        "\n",
        "def mask_by_random_topk(mask_len, probs, temperature=1.0):\n",
        "    confidence = jnp.log(probs) + temperature * jax.random.gumbel(probs.shape)\n",
        "    sorted_confidence = jnp.sort(confidence, axis=-1)\n",
        "    # Obtains cut off threshold given the mask lengths.\n",
        "    cut_off = jnp.take_along_axis(sorted_confidence, mask_len, axis=-1)\n",
        "    # Masks tokens with lower confidence.\n",
        "    masking = (confidence < cut_off)\n",
        "    return masking\n",
        "\n",
        "def decode(inputs, rng, tokens_to_logits, mask_token_id=-1, num_iter=12, choice_temperature=1.0, mask_scheduling_method=\"cosine\"):\n",
        "  \"\"\"Fast decoding for iterative generation.\n",
        "    inputs: int32 array: [batch_size, seq_length] input sequence of masked tokens, where the masking tokens is defined by mask_token_id.\n",
        "    rng: jnp.DeviceArray: sampling random state.\n",
        "    tokens_to_logits: decoder function taking single token slices and cache and returning logits and updated cache.\n",
        "    mask_token_id: int: [Mask] token id.\n",
        "    choice_temperature: float: temperature to control the randomness of masking.\n",
        "  Returns: [batch_size, num_iter, seq_length] output sequence of tokens in all iterations.\n",
        "  \"\"\"\n",
        "  unknown_number_in_the_beginning = jnp.sum(inputs == mask_token_id, axis=-1)\n",
        "  # Initializes state\n",
        "  state = state_init(inputs, rng, num_iter, start_iter=0)\n",
        "\n",
        "  while step < num_iter:\n",
        "    \"\"\"Beam search loop state update function.\"\"\"\n",
        "    # Current input ids: [batch_size, seq_length].\n",
        "    cur_ids = state.cur_seqs\n",
        "\n",
        "    # Calls model on current seqs to get next-iteration seqs.\n",
        "    logits = tokens_to_logits(cur_ids)\n",
        "    # Samples the ids using categorical sampling: [batch_size, seq_length].\n",
        "    sampled_ids = jax.random.categorical(logits) # sample based on softmax(logits)\n",
        "\n",
        "    # Just updates the masked tokens.\n",
        "    unknown_map = (cur_ids == mask_token_id)\n",
        "    sampled_ids = jnp.where(unknown_map, sampled_ids, cur_ids)\n",
        "    # Defines the mask ratio for the next round. The number to mask out is\n",
        "    # determined by mask_ratio * unknown_number_in_the_beginning.\n",
        "    ratio = 1. * (step + 1) / num_iter\n",
        "    # mask_ratio = mask_schedule.schedule(ratio, unknown_number_in_the_beginning, mask_scheduling_method)\n",
        "    mask_ratio = jax.lax.cos(math.pi / 2. * ratio)\n",
        "    mask_ratio = jnp.clip(mask_ratio, 1e-6, 1.)\n",
        "\n",
        "    # Updates final seqs with the current sampled_ids.\n",
        "    final_seqs = jax.lax.dynamic_update_slice(state.final_seqs, jnp.expand_dims(sampled_ids, axis=1), (0, step, 0)) # insert block at pos\n",
        "    # Computes the probabilities of each selected tokens.\n",
        "    probs = jax.nn.softmax(logits, axis=-1) # [b,t,d]\n",
        "    selected_probs = jnp.squeeze(jnp.take_along_axis(probs, jnp.expand_dims(sampled_ids, -1), -1), -1)\n",
        "    # Ignores the tokens given in the input by overwriting their confidence.\n",
        "    selected_probs = jnp.where(unknown_map, selected_probs, _CONFIDENCE_OF_KNOWN_TOKENS)\n",
        "    # Gets mask lens for each sample in the batch according to the mask ratio.\n",
        "    mask_len = jnp.expand_dims(jnp.floor(unknown_number_in_the_beginning * mask_ratio), 1)\n",
        "    # Keeps at least one of prediction in this round and also masks out at least one and for the next iteration\n",
        "    mask_len = jnp.maximum(1, jnp.minimum(jnp.sum(unknown_map, axis=-1, keepdims=True) - 1, mask_len))\n",
        "\n",
        "    # Adds noise for randomness\n",
        "    masking = mask_by_random_topk(mask_len, selected_probs, choice_temperature * (1. - ratio))\n",
        "    # Masks tokens with lower confidence.\n",
        "    sampled_ids = jnp.where(masking, mask_token_id, sampled_ids)\n",
        "    final_state = State(cur_index=state.cur_index + 1, cur_seqs=sampled_ids, rng=rng, final_seqs=final_seqs)\n",
        "  return final_state.final_seqs\n",
        "\n",
        "# start with toks(rest is unk tok), -model> logits, sample to sampled toks\n",
        "# probs=softmax(logits). selected_probs = probs of swelected ind\n",
        "# topk by confidence = jnp.log(selected_probs) + temperature * jax.random.gumbel(rng, probs.shape)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "4Ci931RbUTp1"
      },
      "outputs": [],
      "source": [
        "# @title google-research parallel_decode.py\n",
        "# https://github.com/google-research/maskgit/blob/main/maskgit/libml/parallel_decode.py\n",
        "\n",
        "def mask_by_random_topk(rng=0, mask_len, probs, temperature=1.0):\n",
        "    confidence = jnp.log(probs) + temperature * jax.random.gumbel(rng, probs.shape)\n",
        "    sorted_confidence = jnp.sort(confidence, axis=-1)\n",
        "    # Obtains cut off threshold given the mask lengths.\n",
        "    cut_off = jnp.take_along_axis(sorted_confidence, mask_len.astype(jnp.int32), axis=-1)\n",
        "    # Masks tokens with lower confidence.\n",
        "    masking = (confidence < cut_off)\n",
        "    return masking\n",
        "\n",
        "def decode(inputs, rng, tokens_to_logits, mask_token_id=-1, num_iter=12, start_iter=0, choice_temperature=1.0, mask_scheduling_method=\"cosine\"):\n",
        "  \"\"\"Fast decoding for iterative generation.\n",
        "    inputs: int32 array: [batch_size, seq_length] input sequence of masked tokens, where the masking tokens is defined by mask_token_id.\n",
        "    rng: jnp.DeviceArray: sampling random state.\n",
        "    tokens_to_logits: decoder function taking single token slices and cache and returning logits and updated cache.\n",
        "    mask_token_id: int: [Mask] token id.\n",
        "    num_iter: int: default is 12.\n",
        "    start_iter: int: default is 0.\n",
        "    choice_temperature: float: temperature to control the randomness of masking.\n",
        "    mask_scheduling_method: masking method string. See mask_schedule.py for details.\n",
        "  Returns: [batch_size, num_iter, seq_length] output sequence of tokens in all iterations.\n",
        "  \"\"\"\n",
        "  unknown_number_in_the_beginning = jnp.sum(inputs == mask_token_id, axis=-1)\n",
        "  # Initializes state\n",
        "  state = state_init(inputs, rng, num_iter, start_iter=start_iter)\n",
        "\n",
        "  while state.cur_index < num_iter:\n",
        "    \"\"\"Beam search loop state update function.\"\"\"\n",
        "    rng = state.rng\n",
        "    step = state.cur_index\n",
        "    # Current input ids: [batch_size, seq_length].\n",
        "    cur_ids = state.cur_seqs\n",
        "\n",
        "    # Calls model on current seqs to get next-iteration seqs.\n",
        "    logits = tokens_to_logits(cur_ids)\n",
        "    rng, sample_rng = jax.random.split(rng, 2) # generate an arbitrary number of independent pseudorandom values given a single key\n",
        "    # Samples the ids using categorical sampling: [batch_size, seq_length].\n",
        "    sampled_ids = jax.random.categorical(sample_rng, logits) # sample based on softmax(logits)\n",
        "\n",
        "    # Just updates the masked tokens.\n",
        "    unknown_map = (cur_ids == mask_token_id)\n",
        "    sampled_ids = jnp.where(unknown_map, sampled_ids, cur_ids)\n",
        "    # Defines the mask ratio for the next round. The number to mask out is\n",
        "    # determined by mask_ratio * unknown_number_in_the_beginning.\n",
        "    ratio = 1. * (step + 1) / num_iter\n",
        "    mask_ratio = mask_schedule.schedule(ratio, unknown_number_in_the_beginning, mask_scheduling_method)\n",
        "    # Updates final seqs with the current sampled_ids.\n",
        "    final_seqs = jax.lax.dynamic_update_slice(state.final_seqs, jnp.expand_dims(sampled_ids, axis=1), (0, step, 0)) # insert block at pos\n",
        "    # Computes the probabilities of each selected tokens.\n",
        "    probs = jax.nn.softmax(logits, axis=-1)\n",
        "    selected_probs = jnp.squeeze(jnp.take_along_axis(probs, jnp.expand_dims(sampled_ids.astype(jnp.int32), -1), -1), -1)\n",
        "    # Ignores the tokens given in the input by overwriting their confidence.\n",
        "    selected_probs = jnp.where(unknown_map, selected_probs, _CONFIDENCE_OF_KNOWN_TOKENS)\n",
        "    # Gets mask lens for each sample in the batch according to the mask ratio.\n",
        "    mask_len = jnp.expand_dims(jnp.floor(unknown_number_in_the_beginning * mask_ratio), 1)\n",
        "    # Keeps at least one of prediction in this round and also masks out at least one and for the next iteration\n",
        "    mask_len = jnp.maximum(1, jnp.minimum(jnp.sum(unknown_map, axis=-1, keepdims=True) - 1, mask_len))\n",
        "\n",
        "    # Adds noise for randomness\n",
        "    rng, choice_rng = jax.random.split(rng) # generate an arbitrary number of independent pseudorandom values given a single key\n",
        "    masking = mask_by_random_topk(choice_rng, mask_len, selected_probs, choice_temperature * (1. - ratio))\n",
        "    # Masks tokens with lower confidence.\n",
        "    sampled_ids = jnp.where(masking, mask_token_id, sampled_ids)\n",
        "    final_state = State(cur_index=state.cur_index + 1, cur_seqs=sampled_ids, rng=rng, final_seqs=final_seqs)\n",
        "\n",
        "  return final_state.final_seqs\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "TTnTYDtt2Q78"
      },
      "outputs": [],
      "source": [
        "# @title hmorimitsu/maskgit-torch\n",
        "# https://github.com/hmorimitsu/maskgit-torch/tree/main/maskgit/nets\n",
        "\n",
        "embed = self.blocks(embed)\n",
        "embed = self.Token_Prediction(embed)\n",
        "logits = torch.matmul(embed, self.tok_emb.weight.T)\n",
        "logits = logits + self.bias[None]\n",
        "return logits\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "roofpyd7ImB-"
      },
      "outputs": [],
      "source": [
        "# @title dome272/MaskGIT-pytorch\n",
        "# https://github.com/dome272/MaskGIT-pytorch\n",
        "# https://github.com/dome272/MaskGIT-pytorch/blob/main/transformer.py#L11\n",
        "from transformer import VQGANTransformer\n",
        "\n",
        "class TrainTransformer:\n",
        "    def __init__(self, args):\n",
        "        self.model = VQGANTransformer(args).to(device=args.device)\n",
        "        self.train(args)\n",
        "\n",
        "    def train(self, args):\n",
        "        train_dataset = load_data(args)\n",
        "        len_train_dataset = len(train_dataset)\n",
        "        for epoch in range(args.start_from_epoch+1, args.epochs+1):\n",
        "            print(f\"Epoch {epoch}:\")\n",
        "            with tqdm(range(len(train_dataset))) as pbar:\n",
        "                for i, imgs in zip(pbar, train_dataset):\n",
        "                    imgs = imgs.to(device=args.device)\n",
        "                    logits, target = self.model(imgs)\n",
        "                    loss = F.cross_entropy(logits.reshape(-1, logits.size(-1)), target.reshape(-1))\n",
        "                    loss.backward()\n",
        "                    self.optim.step()\n",
        "                    self.optim.zero_grad()\n",
        "                    pbar.set_postfix(Transformer_Loss=np.round(loss.cpu().detach().numpy().item(), 4))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "uSj4hV_8kAjj"
      },
      "outputs": [],
      "source": [
        "# @title dome272 VQGANTransformer\n",
        "# https://github.com/dome272/MaskGIT-pytorch/blob/main/transformer.py#L11\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import math\n",
        "from bidirectional_transformer import BidirectionalTransformer\n",
        "_CONFIDENCE_OF_KNOWN_TOKENS = torch.Tensor([torch.inf]).to(\"cuda\")\n",
        "\n",
        "\n",
        "class VQGANTransformer(nn.Module):\n",
        "    def __init__(self, args):\n",
        "        super().__init__()\n",
        "        self.num_image_tokens = args.num_image_tokens\n",
        "        self.sos_token = args.num_codebook_vectors + 1\n",
        "        self.mask_token_id = args.num_codebook_vectors\n",
        "        self.choice_temperature = 4.5\n",
        "\n",
        "        self.gamma = self.gamma_func(\"cosine\")\n",
        "\n",
        "        # self.transformer = BidirectionalTransformer(\n",
        "        #                         patch_size=8, embed_dim=args.dim, depth=args.n_layers, num_heads=12, mlp_ratio=4, qkv_bias=True,\n",
        "        #                         norm_layer=partial(nn.LayerNorm, eps=1e-6), vocab_size=8192+1)\n",
        "        self.transformer = BidirectionalTransformer(args)\n",
        "        self.vqgan = self.load_vqgan(args)\n",
        "        print(f\"Transformer parameters: {sum([p.numel() for p in self.transformer.parameters()])}\")\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def encode_to_z(self, x):\n",
        "        # quant_z, indices, _ = self.vqgan.encode(x)\n",
        "        quant_z, _, (_, _, indices) = self.vqgan.encode(x)\n",
        "        indices = indices.view(quant_z.shape[0], -1)\n",
        "        return quant_z, indices\n",
        "\n",
        "    def forward(self, x):\n",
        "        # _, z_indices = self.encode_to_z(x)\n",
        "        #\n",
        "        # r = np.random.uniform()\n",
        "        # mask = torch.bernoulli(r * torch.ones(z_indices.shape[-1], device=z_indices.device))\n",
        "        # mask = mask.round().bool()\n",
        "        #\n",
        "        # target = z_indices[:, mask]\n",
        "        #\n",
        "        # logits = self.transformer(z_indices, mask)\n",
        "\n",
        "        _, z_indices = self.encode_to_z(x)\n",
        "        sos_tokens = torch.ones(x.shape[0], 1, dtype=torch.long, device=z_indices.device) * self.sos_token\n",
        "\n",
        "        r = math.floor(self.gamma(np.random.uniform()) * z_indices.shape[1])\n",
        "        sample = torch.rand(z_indices.shape, device=z_indices.device).topk(r, dim=1).indices\n",
        "        mask = torch.zeros(z_indices.shape, dtype=torch.bool, device=z_indices.device)\n",
        "        mask.scatter_(dim=1, index=sample, value=True)\n",
        "\n",
        "        # torch.rand(z_indices.shape, device=z_indices.device)\n",
        "        # mask = torch.bernoulli(r * torch.ones(z_indices.shape, device=z_indices.device))\n",
        "        # mask = torch.bernoulli(torch.rand(z_indices.shape, device=z_indices.device))\n",
        "        # mask = mask.round().to(dtype=torch.int64)\n",
        "        # masked_indices = torch.zeros_like(z_indices)\n",
        "        masked_indices = self.mask_token_id * torch.ones_like(z_indices, device=z_indices.device)\n",
        "        a_indices = mask * z_indices + (~mask) * masked_indices\n",
        "        a_indices = torch.cat((sos_tokens, a_indices), dim=1)\n",
        "        target = torch.cat((sos_tokens, z_indices), dim=1)\n",
        "        logits = self.transformer(a_indices)\n",
        "        return logits, target\n",
        "\n",
        "    def top_k_logits(self, logits, k):\n",
        "        v, ix = torch.topk(logits, k)\n",
        "        out = logits.clone()\n",
        "        if k == 0: out[:, :] = self.sos_token\n",
        "        else: out[out < v[..., [-1]]] = self.sos_token\n",
        "        return out\n",
        "\n",
        "    def gamma_func(self, mode=\"cosine\"):\n",
        "        if mode == \"linear\": return lambda r: 1 - r\n",
        "        elif mode == \"cosine\": return lambda r: np.cos(r * np.pi / 2)\n",
        "        elif mode == \"square\": return lambda r: 1 - r ** 2\n",
        "        elif mode == \"cubic\": return lambda r: 1 - r ** 3\n",
        "\n",
        "    def create_input_tokens_normal(self, num, label=None):\n",
        "        # label_tokens = label * torch.ones([num, 1])\n",
        "        # Shift the label by codebook_size\n",
        "        # label_tokens = label_tokens + self.vqgan.codebook.num_codebook_vectors\n",
        "        # Create blank masked tokens\n",
        "        blank_tokens = torch.ones((num, self.num_image_tokens), device=\"cuda\")\n",
        "        masked_tokens = self.mask_token_id * blank_tokens\n",
        "        # Concatenate the two as input_tokens\n",
        "        # input_tokens = torch.concat([label_tokens, masked_tokens], dim=-1)\n",
        "        # return input_tokens.to(torch.int32)\n",
        "        return masked_tokens.to(torch.int64)\n",
        "\n",
        "    def tokens_to_logits(self, seq):\n",
        "        logits = self.transformer(seq)\n",
        "        # logits = logits[..., :self.vqgan.codebook.num_codebook_vectors]  # why is maskgit returning [8, 257, 2025]?\n",
        "        return logits\n",
        "\n",
        "    def mask_by_random_topk(self, mask_len, probs, temperature=1.0):\n",
        "        confidence = torch.log(probs) + temperature * torch.distributions.gumbel.Gumbel(0, 1).sample(probs.shape).to(\"cuda\")\n",
        "        sorted_confidence, _ = torch.sort(confidence, dim=-1)\n",
        "        # Obtains cut off threshold given the mask lengths.\n",
        "        cut_off = torch.take_along_dim(sorted_confidence, mask_len.to(torch.long), dim=-1)\n",
        "        # Masks tokens with lower confidence.\n",
        "        masking = (confidence < cut_off)\n",
        "        return masking\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def sample_good(self, inputs=None, num=1, T=11, mode=\"cosine\"):\n",
        "        # self.transformer.eval()\n",
        "        N = self.num_image_tokens\n",
        "        if inputs is None: inputs = self.create_input_tokens_normal(num)\n",
        "        else: inputs = torch.hstack((inputs, torch.zeros((inputs.shape[0], N - inputs.shape[1]), device=\"cuda\", dtype=torch.int).fill_(self.mask_token_id)))\n",
        "\n",
        "        sos_tokens = torch.ones(inputs.shape[0], 1, dtype=torch.long, device=inputs.device) * self.sos_token\n",
        "        inputs = torch.cat((sos_tokens, inputs), dim=1)\n",
        "\n",
        "        unknown_number_in_the_beginning = torch.sum(inputs == self.mask_token_id, dim=-1)\n",
        "        gamma = self.gamma_func(mode)\n",
        "        cur_ids = inputs  # [8, 257]\n",
        "        for t in range(T):\n",
        "            logits = self.tokens_to_logits(cur_ids)  # call transformer to get predictions [8, 257, 1024]\n",
        "            sampled_ids = torch.distributions.categorical.Categorical(logits=logits).sample()\n",
        "\n",
        "            unknown_map = (cur_ids == self.mask_token_id)  # which tokens need to be sampled -> bool [8, 257]\n",
        "            sampled_ids = torch.where(unknown_map, sampled_ids, cur_ids)  # replace all -1 with their samples and leave the others untouched [8, 257]\n",
        "\n",
        "            ratio = 1. * (t + 1) / T  # just a percentage e.g. 1 / 12\n",
        "            mask_ratio = gamma(ratio)\n",
        "\n",
        "            probs = F.softmax(logits, dim=-1)  # convert logits into probs [8, 257, 1024]\n",
        "            selected_probs = torch.squeeze(torch.take_along_dim(probs, torch.unsqueeze(sampled_ids, -1), -1), -1)  # get probability for selected tokens in categorical call, also for already sampled ones [8, 257]\n",
        "\n",
        "            selected_probs = torch.where(unknown_map, selected_probs, _CONFIDENCE_OF_KNOWN_TOKENS)  # ignore tokens which are already sampled [8, 257]\n",
        "\n",
        "            mask_len = torch.unsqueeze(torch.floor(unknown_number_in_the_beginning * mask_ratio), 1)  # floor(256 * 0.99) = 254 --> [254, 254, 254, 254, ....]\n",
        "            mask_len = torch.maximum(torch.zeros_like(mask_len), torch.minimum(torch.sum(unknown_map, dim=-1, keepdim=True)-1, mask_len))  # add -1 later when conditioning and also ones_like. Zeroes just because we have no cond token\n",
        "            # max(1, min(how many unknown tokens, how many tokens we want to sample))\n",
        "\n",
        "            # Adds noise for randomness\n",
        "            masking = self.mask_by_random_topk(mask_len, selected_probs, temperature=self.choice_temperature * (1. - ratio))\n",
        "            # Masks tokens with lower confidence.\n",
        "            cur_ids = torch.where(masking, self.mask_token_id, sampled_ids)\n",
        "            # print((cur_ids == 8192).count_nonzero())\n",
        "        # self.transformer.train()\n",
        "        return cur_ids[:, 1:]\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def log_images(self, x, mode=\"cosine\"):\n",
        "        log = dict()\n",
        "        _, z_indices = self.encode_to_z(x)\n",
        "        # create new sample\n",
        "        index_sample = self.sample_good(mode=mode)\n",
        "        x_new = self.indices_to_image(index_sample)\n",
        "\n",
        "        # create a \"half\" sample\n",
        "        z_start_indices = z_indices[:, :z_indices.shape[1] // 2]\n",
        "        half_index_sample = self.sample_good(z_start_indices, mode=mode)\n",
        "        x_sample = self.indices_to_image(half_index_sample)\n",
        "\n",
        "        # create reconstruction\n",
        "        x_rec = self.indices_to_image(z_indices)\n",
        "\n",
        "\n",
        "    def indices_to_image(self, indices, p1=32, p2=32):\n",
        "        ix_to_vectors = self.vqgan.codebook.embedding(indices).reshape(indices.shape[0], p1, p2, 32)\n",
        "        # ix_to_vectors = self.vqgan.quantize.embedding(indices).reshape(indices.shape[0], 16, 16, 256)\n",
        "        ix_to_vectors = ix_to_vectors.permute(0, 3, 1, 2)\n",
        "        image = self.vqgan.decode(ix_to_vectors)\n",
        "        return image\n",
        "\n",
        "    @staticmethod\n",
        "    def create_masked_image(image: torch.Tensor, x_start: int = 100, y_start: int = 100, size: int = 50):\n",
        "        mask = torch.ones_like(image, dtype=torch.int)\n",
        "        mask[:, :, x_start:x_start + size, y_start:y_start + size] = 0\n",
        "        return image * mask, mask\n",
        "\n",
        "    def inpainting(self, image: torch.Tensor, x_start: int = 100, y_start: int = 100, size: int = 50):\n",
        "        # Note: this function probably doesnt work yet lol\n",
        "        # apply mask on image\n",
        "        masked_image, mask = self.create_masked_image(image, x_start, y_start, size)\n",
        "\n",
        "        # encode masked image\n",
        "        # _, indices = self.encode_to_z(masked_image)\n",
        "        indices = torch.randint(1024, (1, 256), dtype=torch.int)\n",
        "        mask = mask[:, 0, :, :]\n",
        "\n",
        "        # set masked patches to be 0 -> so that the sampling part only samples indices for these patches\n",
        "        # 1. idea: just calculate the ratio between 256x256 image and 16x16 latent image and set the area\n",
        "        #          which was masked in the original image to 0 in the encoded image\n",
        "        # 2. idea: check if patches which were masked in the original image are always the same in the latent space\n",
        "        #          If so: set these to 0\n",
        "        p = 16\n",
        "        patched_mask = mask.unfold(2, p, p).unfold(1, p, p)\n",
        "        patched_mask = torch.transpose(patched_mask, 3, 4)\n",
        "        patched_mask = patched_mask.permute(1, 2, 0, 3, 4)\n",
        "        patched_mask = patched_mask.contiguous().view(patched_mask.size(0) * patched_mask.size(1), -1)  # 256 x 256 i.e. 16x16 x 256\n",
        "\n",
        "        indices_mask, _ = torch.min(patched_mask, dim=-1)\n",
        "        indices = indices_mask * indices\n",
        "\n",
        "        # inpaint the image by using the sample method and provide the masked image indices and condition\n",
        "        sampled_indices = self.sample(indices)\n",
        "\n",
        "        # reconstruct inpainted image\n",
        "        inpainted_image = self.indices_to_image(sampled_indices)\n",
        "\n",
        "        # linearly blend the input image and inpainted image at border of mask (to avoid sharp edges at border of mask)\n",
        "        indices_mask = indices_mask.reshape(1, 1, 16, 16).type(torch.float)\n",
        "        upsampled_indices_mask = F.interpolate(indices_mask, scale_factor=16).squeeze(0)\n",
        "        intra = torch.where(mask != upsampled_indices_mask, 1, 0)\n",
        "\n",
        "        # define mask for blending\n",
        "        n = 128\n",
        "        base = torch.arange(n).view(1, -1).max(torch.arange(n).view(-1, 1))\n",
        "        right = torch.stack((torch.rot90(base, 1, [0, 1]), base)).reshape(n * 2, n)\n",
        "        left = torch.stack((torch.rot90(base, 2, [0, 1]), torch.rot90(base, 3, [0, 1]))).reshape(n * 2, n)\n",
        "        full = torch.cat((left, right), 1)\n",
        "\n",
        "        # construct opacity matrix for intra region\n",
        "        min_blend = torch.min(torch.where(intra == 1, full, 1000000))\n",
        "        max_blend = torch.max(torch.where(intra == 1, full, -1000000))\n",
        "        mask_blend = torch.where(intra == 1, (full - min_blend) / max_blend, torch.ones_like(intra, dtype=torch.float))\n",
        "\n",
        "        mask_real = torch.where(mask == 0, mask.type(torch.float), mask_blend)\n",
        "        mask_fake = torch.where(mask == 0, (1 - mask).type(torch.float), mask_blend)\n",
        "\n",
        "        blended_image = mask_real * image + mask_fake * inpainted_image\n",
        "        return blended_image, inpainted_image\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lyI8UKduqeBw"
      },
      "source": [
        "## trash"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Mje-yFj88WlY"
      },
      "outputs": [],
      "source": [
        "# @title FSQ me fuse\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "def ste_round(x): return x.round().detach() + x - x.detach()\n",
        "\n",
        "class FSQ(nn.Module):\n",
        "    def __init__(self, levels):\n",
        "        super().__init__()\n",
        "        self.levels = torch.tensor(levels, device=device)\n",
        "        self.basis = torch.cumprod(torch.tensor([*levels[1:], 1], device=device).flip(-1), dim=0).flip(-1)\n",
        "        self.half_width = (self.levels-1)/2\n",
        "        self.codebook_size = torch.prod(self.levels).item()\n",
        "        self.codebook = self.indexes_to_codes(torch.arange(self.codebook_size, device=device))\n",
        "        self.offset = (self.levels+1) % 2 /2 # .5 if even, 0 if odd\n",
        "        self.beta = 1.0#1 # beta in (0,1). beta->0 => values more spread out\n",
        "\n",
        "    def forward(self, z):\n",
        "        # bound = (F.sigmoid(z)-1/2) * (self.levels-self.beta) + self.offset\n",
        "        bound = (F.tanh(z)/2) * (self.levels-self.beta) + self.offset\n",
        "        # print('fwd', bound) #\n",
        "        quantized = ste_round(bound)\n",
        "        # print('fwd', quantized) # 4: -1012\n",
        "        return (quantized-self.offset) / self.half_width # split [-1,1]\n",
        "\n",
        "    def codes_to_indexes(self, zhat):\n",
        "        zhat = (zhat + 1) * self.half_width\n",
        "        # zhat = quantized - self.offset + self.half_width\n",
        "        # print('codes_to_indexes', zhat)\n",
        "        return (zhat * self.basis).sum(axis=-1).round().int()\n",
        "\n",
        "    def indexes_to_codes(self, indices):\n",
        "        indices = indices.unsqueeze(-1)\n",
        "        codes = torch.remainder(indices//self.basis, self.levels)\n",
        "        # print(\"codes\",codes)\n",
        "        return codes / self.half_width - 1\n",
        "\n",
        "# fsq = FSQ(levels = [5,4,3,2])\n",
        "fsq = FSQ(levels = [16,4,3,2])\n",
        "# print(fsq.codebook)\n",
        "batch_size, seq_len = 2, 4\n",
        "# x = torch.rand((batch_size, seq_len,3),device=device)\n",
        "x = torch.linspace(-2,2,12, device=device).repeat(4,1).T\n",
        "# x = torch.linspace(-1,1,17, device=device).repeat(4,1).T\n",
        "# x = torch.linspace(-20,20,12, device=device).repeat(4,1).T\n",
        "la = fsq(x)\n",
        "# la = la[1]\n",
        "# print(la)\n",
        "\n",
        "# la = torch.tensor([1.2982, 0.9252, 1.4062, 1.2679])\n",
        "\n",
        "lact = fsq.codes_to_indexes(la)\n",
        "print(lact)\n",
        "la_ = fsq.indexes_to_codes(lact)\n",
        "print(la_)\n",
        "# print(la-la_)\n",
        "# mask = ((la-la_).abs()<1e-6)\n",
        "# print(((la-la_).abs()<1e-7).all())\n",
        "# print((~mask).nonzero())\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "EhSU2YKrbt6K",
        "sND7C1rq4nEg"
      ],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}